# Must Learn AI Security - the blog series, the book, the store<br>
<p align="right"><img src="https://github.com/rod-trent/OpenAISecurity/blob/main/Must_Learn/Series_Images/MustLearnAISecuritySmallSmall.png" alt="Must Learn AI Security"></center></p>

This repository contains the content, code, queries, and eBook (coming) included as part of the Must Learn AI Security series. The series is a continuing effort to discuss and educate about how to monitor and secure Artificial Intelligence.

The series has it's own shortlink. To return back here, just remember the easy URL: https://aka.ms/MustLearnAISecurity

The eBook (PDF) is updated whenever changes are made or new parts of the series are released. Get the book: https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version

Love the series so much you want a coffee mug? There's now a <b>merch store</b> where all proceeds go to <a href="https://www.stjude.org/" target="_blank">St. Jude Children's Research Hospital.</a> Check it out! <b><a href="https://must-learn-kql.creator-spring.com" target="_blank">MUST LEARN STORE</a></b>

<b><h1>Table of Contents</h1></b>
The following are links to the entire series so far:
<br><br>

* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-series-introduction" target="_blank">Must Learn AI Security Series: Introduction</a> - <i>Posted August 1, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-1-prompt" target="_blank">Must Learn AI Security Part 1: Prompt Injection Attacks Against AI</a> - <i>Posted August 1, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-2-data" target="_blank">Must Learn AI Security Part 2: Data Poisoning Attacks Against AI</a> - <i>Posted August 8, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-3-adversarial" target="_blank">Must Learn AI Security Part 3: Adversarial Attacks Against AI</a> - <i>Posted August 15, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-4-trojan" target="_blank">Must Learn AI Security Part 4: Trojan Attacks Against AI</a> - <i>Posted August 21, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-5-evasion" target="_blank">Must Learn AI Security Part 5: Evasion Attacks Against AI</a> - <i>Posted August 22, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-6-model" target="_blank">Must Learn AI Security Part 6: Model Inversion Attacks Against AI</a> - <i>Posted August 23, 2023</i><br>
* <a href="https://rodtrent.substack.com/p/must-learn-ai-security-part-7-membership" target="_blank">Must Learn AI Security Part 7: Membership Inference Attacks Against AI</a> - <i>Posted August 24, 2023</i><br>
* Model stealing: Copying the functionality of a proprietary model without access to its parameters. <i>Expected September 5, 2023</i><br>
* Hyperparameter attacks: Tampering with the parameters that control the learning process.
* Backdoor attacks: Sneaking in hidden functionality that can be triggered later.
* Denial of service: Overwhelming an AI system with requests to make it unresponsive.
* Reward hacking: Exploiting a reinforcement learning model's reward function.
* Generative attacks: Creating fake data to deceive or manipulate.
* Inference attacks: Extracting sensitive information from AI-generated outputs.
* Misinformation: Spreading fake or misleading information through AI-generated content.
* Impersonation: Using AI-generated content to mimic a real person.
* Social engineering: Manipulating people through AI-generated content.
* AI bias exploitation: Taking advantage of biases present in AI models.
* AI-generated deepfakes: Creating realistic fake videos or audio clips.
* Text-based attacks: Generating malicious or misleading text using AI.
* Watermark removal: Using AI to remove watermarks from protected content.

<br><br>

<b><h1>Frequently Asked Questions (FAQ)</h1></b>
Q. Is there a downloadable version of the series?
<br>
A. Yes. There is an eBook version of the series that gets updated everytime a new chatper is posted. The eBook is located here: https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version
<br><br>
Q. Will there be a physical copy of the book? 
<br>
A. Yes. Just like was done for the <a href="https://aka.ms/MustLearnKQL" target="_blank">Must Learn KQL</a>series, when this series is complete, a physical copy (hardcover and softcover) will be available for purchase from Amazon. And, also like the Must Learn KQL version, all proceeds go to <a href="https://www.stjude.org/" target="_blank">St. Jude Children's Research Hospital</a>. 
<br><br>
Q. How many chapters will there be?
<br>
A. I'm not sure yet. I have a general sense of the length and what needs to be covered, but since this is an ongoing effort and this space is constantly evolving and changing, only time will tell.
<br><br>
Q. How do I know I have the most current version of the eBook?
<br>
A. Compare the versioning information on the eBook's download page to the versioning information inside the eBook.
<br><br>
</br></br></br>
<p align="center"><img src="https://github.com/rod-trent/OpenAISecurity/blob/main/Must_Learn/Series_Images/Must%20Learn%20AI%20Security%20Small.png?raw=true" alt="Must Learn AI Security"></center></p>
